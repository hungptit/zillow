* TODO Setup a cron job which will crawl house information daily from zillow.com.
* TODO Have a C++ client which allow users to add zpid to the database i.e add_house_zpid.
* TODO Web interface which can produce a reasonable report.
* TODO Before query any house need to check that it information is exist in the database first. We might need to change house address to lowercase.
* TODO How to apply machine learning algorithms to predict the sale and the area that we need to focus?
* TODO How to import data from Redfin?
* TODO Save all raw data to rocksdb. There are three databases which are DeepSearchResults, DeepCompsResults, and UpdatedPropertiesDetail. The key is zpid-crawl-date.
* TODO From a excel file write the output data in JSON format that can be understandable by cereal. Information will be imported to a vector of tuples.
* TODO Only use MATLAB to do some Excel related tasks.
* TODO How to compute the score between two houses
* TODO SaleRecord will has these information: SellerAgent, BuyerAgent, SoldDate, SoldPrice, SoldPriceCurrency, Notes (random notes collected from users)
* TODO Have a undirected weighted graph data structure to store DeepComps results.
* TODO Write a mobile app that can give users information related to a house and/or area. It also give users pleminary advice about buying a house for living and/or investment.
* TODO A client which can automatically crawl all house information related to a given house must be in the same town?
** Use BFS strategy. We will need to remove nodes which are not in the same town.
** A web crawler will need to operate on the string stream. We should not create unneccesary temporary data.
* TODO Save all raw data to DeepSearchResults, DeepCompsResults, and UpdatedDetailsResults leveldb database.
* TODO Serialize all processed data into leveldb + sqlite databases?
* TODO We will saved all raw data to leveldb and save all processed data to both leveldb and sqlite. We might need to reprocess the raw data to update all databases.
* TODO Have a parser for the UpdatedPropertyDetails data.
* TODO Have the final design for a web crawler that can
** Craw data automatically based on the suggested house.
** Automatically update house detail information in a separate thread using UpdatedPropertyDetails API.
** Automatically fix or update house information using DeepSearchResults API in a separate thread.
** Automatically update the SQLite and leveldb database.
** Must be thread safe and need to have high performance.
** Can comunicate with the client -> get seed and some special commands such as update date for a given town.
** Can crawl data for a given town (limit the solution space -> save query count).
* TODO Creae a list of email that can be used to query data from zillow. For example zillow-needham, zillow-springfield, zillow-enfield. The web crawler will be executed automatically to crawl latest from for these databases.
